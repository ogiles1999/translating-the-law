{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b165e714-fe7c-42ee-b6c8-8cfce2b272c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from translating_the_law.utils.get_from_disk import open_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d14d92b-b6c0-4c02-8a02-eb126ca4f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.utils import common_texts\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70ecf16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c07694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c875692-ff96-4c12-b07b-578da051802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_data = open_from_disk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9345df9-0989-43d1-bace-a1e437669429",
   "metadata": {},
   "source": [
    "Basic data is a list and each item inside the list is a dictionary with these keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "164b8681-cbc9-4637-b33a-a11e65f62cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['judgement', 'press summary', 'details'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_data[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93cd13d",
   "metadata": {},
   "source": [
    "#### Copy dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fb64c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "judg_data = [basic_data[i][\"judgement\"]['body'] for i in range(len(basic_data))]\n",
    "dfc = pd.DataFrame(judg_data).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665c03a8",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e039df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hilary Term [2022] UKSC 6 On appeal from: [202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The reporting restrictions made by the High Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hilary Term [2022] UKSC 2 On appeal from: [202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hilary Term [2022] UKSC 2 On appeal from: [202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE COURT ORDERED that no one shall publish or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Hilary Term [2022] UKSC 6 On appeal from: [202...\n",
       "1  The reporting restrictions made by the High Co...\n",
       "2  Hilary Term [2022] UKSC 2 On appeal from: [202...\n",
       "3  Hilary Term [2022] UKSC 2 On appeal from: [202...\n",
       "4  THE COURT ORDERED that no one shall publish or..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53ca5d5",
   "metadata": {},
   "source": [
    "#### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa40dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hilary Term [2022] UKSC 6 On appeal from: [202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The reporting restrictions made by the High Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hilary Term [2022] UKSC 2 On appeal from: [202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hilary Term [2022] UKSC 2 On appeal from: [202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE COURT ORDERED that no one shall publish or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Hilary Term [2022] UKSC 6 On appeal from: [202...\n",
       "1  The reporting restrictions made by the High Co...\n",
       "2  Hilary Term [2022] UKSC 2 On appeal from: [202...\n",
       "3  Hilary Term [2022] UKSC 2 On appeal from: [202...\n",
       "4  THE COURT ORDERED that no one shall publish or..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc = dfc.rename(columns={0 : 'text'})\n",
    "dfc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b52a81f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    for punctuation in string.punctuation: \n",
    "        text = text.replace(punctuation, ' ') \n",
    "    return text\n",
    "\n",
    "dfc['clean_text'] = dfc.text.apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b862d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(text, **kwargs):\n",
    "  \"\"\"params is a list of things to remove: codec, acronyms, numbers, brackets\"\"\"\n",
    "  if 'codec' in kwargs['params']:\n",
    "    text_encoded = text.encode('ascii', errors = 'ignore')\n",
    "    text_decode = text_encoded.decode()\n",
    "    clean_text = \" \".join([word for word in text_decode.split()])\n",
    "    text = clean_text\n",
    "  if 'numbers' in kwargs['params']:\n",
    "    pattern = r'[0-9]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "  if 'brackets' in kwargs['params']: \n",
    "    text = re.sub('\\(.*?\\)', '', text)\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "  if 'acronyms' in kwargs['params']:\n",
    "    text = text.split()\n",
    "    clean_text = []\n",
    "    for word in text: \n",
    "      if any(l.islower() for l in word):\n",
    "        clean_text.append(word)\n",
    "    text = ' '.join(clean_text)\n",
    "  return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f046834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['codec', 'numbers', 'acronyms', 'brackets']\n",
    "for i in range(len(dfc['clean_text'])):\n",
    "    strg = dfc['clean_text'][i]\n",
    "    dfc['clean_text'][i] = cleaner(strg, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e789e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hilary Term [2022] UKSC 6 On appeal from: [202...</td>\n",
       "      <td>hilary term on appeal from craig appellant v h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The reporting restrictions made by the High Co...</td>\n",
       "      <td>the reporting restrictions made by the high co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hilary Term [2022] UKSC 2 On appeal from: [202...</td>\n",
       "      <td>hilary term on appeal from admin pwr appellant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hilary Term [2022] UKSC 2 On appeal from: [202...</td>\n",
       "      <td>hilary term on appeal from admin pwr appellant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE COURT ORDERED that no one shall publish or...</td>\n",
       "      <td>that no one shall publish or reveal the names ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>Michaelmas Term [2009] UKSC 15  On appeal from...</td>\n",
       "      <td>michaelmas term on appeal from civ on the appl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>Michaelmas Term [2009] UKSC 16 On appeal from:...</td>\n",
       "      <td>michaelmas term on appeal from civ civ ahmed m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>Michaelmas Term [2009] UKSC 16 On appeal from:...</td>\n",
       "      <td>michaelmas term on appeal from civ civ ahmed m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>Michaelmas Term [2009] UKSC 16 On appeal from:...</td>\n",
       "      <td>michaelmas term on appeal from civ civ ahmed m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>Michaelmas Term [2009] UKSC 17 On appeal from:...</td>\n",
       "      <td>michaelmas term on appeal from civ children be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>946 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    Hilary Term [2022] UKSC 6 On appeal from: [202...   \n",
       "1    The reporting restrictions made by the High Co...   \n",
       "2    Hilary Term [2022] UKSC 2 On appeal from: [202...   \n",
       "3    Hilary Term [2022] UKSC 2 On appeal from: [202...   \n",
       "4    THE COURT ORDERED that no one shall publish or...   \n",
       "..                                                 ...   \n",
       "941  Michaelmas Term [2009] UKSC 15  On appeal from...   \n",
       "942  Michaelmas Term [2009] UKSC 16 On appeal from:...   \n",
       "943  Michaelmas Term [2009] UKSC 16 On appeal from:...   \n",
       "944  Michaelmas Term [2009] UKSC 16 On appeal from:...   \n",
       "945  Michaelmas Term [2009] UKSC 17 On appeal from:...   \n",
       "\n",
       "                                            clean_text  \n",
       "0    hilary term on appeal from craig appellant v h...  \n",
       "1    the reporting restrictions made by the high co...  \n",
       "2    hilary term on appeal from admin pwr appellant...  \n",
       "3    hilary term on appeal from admin pwr appellant...  \n",
       "4    that no one shall publish or reveal the names ...  \n",
       "..                                                 ...  \n",
       "941  michaelmas term on appeal from civ on the appl...  \n",
       "942  michaelmas term on appeal from civ civ ahmed m...  \n",
       "943  michaelmas term on appeal from civ civ ahmed m...  \n",
       "944  michaelmas term on appeal from civ civ ahmed m...  \n",
       "945  michaelmas term on appeal from civ children be...  \n",
       "\n",
       "[946 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lowercase (text): \n",
    "    lowercased = text.lower() \n",
    "    return lowercased\n",
    "\n",
    "dfc['clean_text'] = dfc.clean_text.apply(lowercase)\n",
    "\n",
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1003a3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the united states of GPE\n",
      "america GPE\n",
      "lloyd jones ORG\n",
      "kitchin PERSON\n",
      "november DATE\n",
      "dunne defence st PERSON\n",
      "the united states GPE\n",
      "america GPE\n",
      "kenny PERSON\n",
      "scotland GPE\n",
      "kitchin PERSON\n",
      "scottish NORP\n",
      "scotland GPE\n",
      "the european convention ORG\n",
      "the united kingdom GPE\n",
      "a period of years DATE\n",
      "october DATE\n",
      "scott baker PERSON\n",
      "the house of commons home affairs committee ORG\n",
      "some months later DATE\n",
      "scott PERSON\n",
      "october DATE\n",
      "february DATE\n",
      "one CARDINAL\n",
      "the united kingdom GPE\n",
      "the united kingdom GPE\n",
      "the united kingdom GPE\n",
      "the united kingdom GPE\n",
      "the united kingdom GPE\n",
      "one CARDINAL\n",
      "one CARDINAL\n",
      "the united kingdom GPE\n",
      "the united kingdom GPE\n",
      "the united kingdom GPE\n",
      "the united states GPE\n",
      "america GPE\n",
      "one CARDINAL\n",
      "two CARDINAL\n",
      "secondly ORDINAL\n",
      "scotland GPE\n",
      "such day DATE\n",
      "days DATE\n",
      "northern ireland GPE\n",
      "october DATE\n",
      "scottish NORP\n",
      "scottish NORP\n",
      "scottish NORP\n",
      "the day DATE\n",
      "the house of commons ORG\n",
      "scottish NORP\n",
      "scotland GPE\n",
      "scottish NORP\n",
      "december DATE\n",
      "scottish NORP\n",
      "scotland GPE\n",
      "scottish NORP\n",
      "daily DATE\n",
      "december DATE\n",
      "scottish NORP\n",
      "james craig PERSON\n",
      "british NORP\n",
      "scotland GPE\n",
      "scotland GPE\n",
      "scottish NORP\n",
      "one CARDINAL\n",
      "scotland GPE\n",
      "june DATE\n",
      "scotland GPE\n",
      "scotland act ORG\n",
      "scottish NORP\n",
      "scotland GPE\n",
      "scotland GPE\n",
      "scottish NORP\n",
      "malcolm PERSON\n",
      "scotland GPE\n",
      "such day DATE\n",
      "days DATE\n",
      "state ORG\n",
      "scottish NORP\n",
      "malcolm PERSON\n",
      "third ORDINAL\n",
      "scottish NORP\n",
      "scottish NORP\n",
      "malcolm PERSON\n",
      "six months later DATE\n",
      "june DATE\n",
      "the scotland act paragraph d ORG\n",
      "scottish NORP\n",
      "scottish NORP\n",
      "scottish NORP\n",
      "july DATE\n",
      "scottish NORP\n",
      "september DATE\n",
      "scottish NORP\n",
      "brodie PERSON\n",
      "january DATE\n",
      "june DATE\n",
      "scotland GPE\n",
      "august DATE\n",
      "september DATE\n",
      "july DATE\n",
      "july DATE\n",
      "two CARDINAL\n",
      "two CARDINAL\n",
      "first ORDINAL\n",
      "june DATE\n",
      "the scotland act ORG\n",
      "scotland GPE\n",
      "the scotland act ORG\n",
      "secondly ORDINAL\n",
      "scottish NORP\n",
      "the supreme court ORG\n",
      "the supreme court ORG\n",
      "malcolm PERSON\n",
      "scotland GPE\n",
      "september DATE\n",
      "first ORDINAL\n",
      "malcolm PERSON\n",
      "scottish NORP\n",
      "scotland parliament ORG\n",
      "secondly ORDINAL\n",
      "malcolm PERSON\n",
      "first ORDINAL\n",
      "scotland GPE\n",
      "one CARDINAL\n",
      "rwanda GPE\n",
      "scottish NORP\n",
      "first ORDINAL\n",
      "st georges healthcare trust ORG\n",
      "scottish NORP\n",
      "scottish NORP\n",
      "three CARDINAL\n",
      "secondly ORDINAL\n",
      "first ORDINAL\n",
      "the european court of human ORG\n",
      "united kingdom GPE\n",
      "first ORDINAL\n",
      "first ORDINAL\n",
      "third ORDINAL\n",
      "scottish NORP\n",
      "malcolm PERSON\n",
      "scottish NORP\n",
      "scotland GPE\n",
      "september DATE\n"
     ]
    }
   ],
   "source": [
    "text = nlp(dfc['clean_text'][0])\n",
    "for w in text.ents:\n",
    "    print(w.text,w.label_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "992e4c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_ent = nlp.pipe_labels['ner']\n",
    "lst_rem_ent = ['PERSON', 'GPE', 'LOC', 'DATE', 'CARDINAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e847dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(text):\n",
    "    text = nlp(text)\n",
    "    new_str = ''\n",
    "    for w in text.ents:\n",
    "        if w.label_ not in lst_rem_ent:\n",
    "            new_str += str(w.text) + \" \"\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b9677e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_2(text):\n",
    "    text = nlp(text)\n",
    "    new_lst = []\n",
    "    for w in text.ents:\n",
    "        if w.label_ in lst_rem_ent:\n",
    "            new_lst.append(w.text)\n",
    "    return new_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710149f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_try = filtering_2(dfc['clean_text'][0])\n",
    "first_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ebbb084",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "\n",
    "def filter_final(text):\n",
    "    delete_words = filtering_2(text)\n",
    "    tokenized = word_tokenize(text)\n",
    "    without_stopwords = [word for word in tokenized if not word in stop_words]\n",
    "    with_filter = [word for word in without_stopwords if not word in delete_words]\n",
    "    return with_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44c6a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc['clean_text'] = dfc.clean_text.apply(filter_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4635b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hilary'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc['clean_text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91275101",
   "metadata": {},
   "source": [
    "#### get a list of lists of words and lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "587b70b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hilary Term [2022] UKSC 6 On appeal from: [202...</td>\n",
       "      <td>[lloyd, jones, scottish, european, convention,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The reporting restrictions made by the High Co...</td>\n",
       "      <td>[lloyd, jones, bloomberg, news, one, bloomberg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hilary Term [2022] UKSC 2 On appeal from: [202...</td>\n",
       "      <td>[lloyd, jones, birnberg, peirce, ltd, european...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hilary Term [2022] UKSC 2 On appeal from: [202...</td>\n",
       "      <td>[lloyd, jones, birnberg, peirce, ltd, european...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE COURT ORDERED that no one shall publish or...</td>\n",
       "      <td>[british, british, government, legal, departme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Hilary Term [2022] UKSC 6 On appeal from: [202...   \n",
       "1  The reporting restrictions made by the High Co...   \n",
       "2  Hilary Term [2022] UKSC 2 On appeal from: [202...   \n",
       "3  Hilary Term [2022] UKSC 2 On appeal from: [202...   \n",
       "4  THE COURT ORDERED that no one shall publish or...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  [lloyd, jones, scottish, european, convention,...  \n",
       "1  [lloyd, jones, bloomberg, news, one, bloomberg...  \n",
       "2  [lloyd, jones, birnberg, peirce, ltd, european...  \n",
       "3  [lloyd, jones, birnberg, peirce, ltd, european...  \n",
       "4  [british, british, government, legal, departme...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "\n",
    "def remove_stopwords (text):\n",
    "    tokenized = word_tokenize(text)\n",
    "    without_stopwords = [word for word in tokenized if not word in stop_words]\n",
    "    return without_stopwords\n",
    "\n",
    "dfc['clean_text'] = dfc.clean_text.apply(remove_stopwords)\n",
    "\n",
    "dfc.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d64f975b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lloyd',\n",
       " 'jones',\n",
       " 'bloomberg',\n",
       " 'news',\n",
       " 'one',\n",
       " 'bloomberg',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'bloomberg',\n",
       " 'one',\n",
       " 'united',\n",
       " 'nation',\n",
       " 'convention',\n",
       " 'third',\n",
       " 'three',\n",
       " 'four',\n",
       " 'ltd',\n",
       " 'board',\n",
       " 'bloomberg',\n",
       " 'european',\n",
       " 'two',\n",
       " 'first',\n",
       " 'secondly',\n",
       " 'two',\n",
       " 'two',\n",
       " 'one',\n",
       " 'two',\n",
       " 'bloomberg',\n",
       " 'bloomberg',\n",
       " 'one',\n",
       " 'one',\n",
       " 'two',\n",
       " 'two',\n",
       " 'campbell',\n",
       " 'v',\n",
       " 'ltd',\n",
       " 'douglas',\n",
       " 'v',\n",
       " 'hello',\n",
       " 'ltd',\n",
       " 'two',\n",
       " 'one',\n",
       " 'two',\n",
       " 'two',\n",
       " 'two',\n",
       " 'european',\n",
       " 'court',\n",
       " 'human',\n",
       " 'right',\n",
       " 'ecthr',\n",
       " 'supreme',\n",
       " 'court',\n",
       " 'newspaper',\n",
       " 'ltd',\n",
       " 'civ',\n",
       " 'para',\n",
       " 'one',\n",
       " 'one',\n",
       " 'axel',\n",
       " 'axel',\n",
       " 'first',\n",
       " 'one',\n",
       " 'first',\n",
       " 'second',\n",
       " 'third',\n",
       " 'fourth',\n",
       " 'two',\n",
       " 'fifth',\n",
       " 'one',\n",
       " 'first',\n",
       " 'second',\n",
       " 'bloomberg',\n",
       " 'bloomberg',\n",
       " 'bloomberg',\n",
       " 'bloomberg',\n",
       " 'one',\n",
       " 'bloomberg',\n",
       " 'first',\n",
       " 'one',\n",
       " 'two',\n",
       " 'second',\n",
       " 'third',\n",
       " 'fourth',\n",
       " 'first',\n",
       " 'second',\n",
       " 'third',\n",
       " 'fourth',\n",
       " 'first',\n",
       " 'one',\n",
       " 'general',\n",
       " 'v',\n",
       " 'ltd',\n",
       " 'admin',\n",
       " 'second',\n",
       " 'house',\n",
       " 'common',\n",
       " 'home',\n",
       " 'affair',\n",
       " 'committee',\n",
       " 'seventeenth',\n",
       " 'first',\n",
       " 'british',\n",
       " 'newspaper',\n",
       " 'ltd',\n",
       " 'nicklin',\n",
       " 'nicklin',\n",
       " 'bloomberg',\n",
       " 'khuja',\n",
       " 'v',\n",
       " 'time',\n",
       " 'newspaper',\n",
       " 'ltd',\n",
       " 'first',\n",
       " 'khuja',\n",
       " 'time',\n",
       " 'khuja',\n",
       " 'one',\n",
       " 'wilson',\n",
       " 'khujas',\n",
       " 'one',\n",
       " 'bloomberg',\n",
       " 'bloomberg',\n",
       " 'bloomberg',\n",
       " 'diautas',\n",
       " 'v',\n",
       " 'lithuania',\n",
       " 'axel',\n",
       " 'gillberg',\n",
       " 'v',\n",
       " 'sweden',\n",
       " 'axel',\n",
       " 'axel',\n",
       " 'first',\n",
       " 'diautas',\n",
       " 'v',\n",
       " 'lithuania',\n",
       " 'general',\n",
       " 'medical',\n",
       " 'council',\n",
       " 'one',\n",
       " 'bloomberg',\n",
       " 'first',\n",
       " 'two',\n",
       " 'second',\n",
       " 'bloomberg',\n",
       " 'asserts',\n",
       " 'bloomberg',\n",
       " 'para',\n",
       " 'two',\n",
       " 'two',\n",
       " 'brevan',\n",
       " 'howard',\n",
       " 'asset',\n",
       " 'reuters',\n",
       " 'ltd',\n",
       " 'civ',\n",
       " 'one',\n",
       " 'axel']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemma(text):\n",
    "    lemmatizer = WordNetLemmatizer() # Initiate lemmatizer\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in text] # Lemmatize\n",
    "    return lemmatized\n",
    "\n",
    "dfc['clean_text'] = dfc.clean_text.apply(lemma)\n",
    "\n",
    "dfc['clean_text'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad0639b",
   "metadata": {},
   "source": [
    "# Preprocessing Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371eb663",
   "metadata": {},
   "source": [
    "Get a list of all the words that we know won't be used to extract context and will mislead our feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67208338",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_remove = [\n",
    "'hilary', 'term', 'appeal', 'page', 'lord', 'lady', 'pwr',\n",
    " 'michaelmas', 'uksc', 'civ', 'ewca', 'president', 'appealant', 'court', 'judge', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f60aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_final(lst):\n",
    "    res = []\n",
    "    for word in lst:\n",
    "        if word in word_to_remove:\n",
    "            lst.remove(word)\n",
    "        if word not in res:\n",
    "            res.append(word)\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "317ffdd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hilary Term [2022] UKSC 6 On appeal from: [202...</td>\n",
       "      <td>[lloyd, jones, scottish, european, convention,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The reporting restrictions made by the High Co...</td>\n",
       "      <td>[lloyd, jones, bloomberg, news, one, supreme, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hilary Term [2022] UKSC 2 On appeal from: [202...</td>\n",
       "      <td>[lloyd, jones, birnberg, peirce, ltd, european...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hilary Term [2022] UKSC 2 On appeal from: [202...</td>\n",
       "      <td>[lloyd, jones, birnberg, peirce, ltd, european...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE COURT ORDERED that no one shall publish or...</td>\n",
       "      <td>[british, government, legal, department, amnes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>Michaelmas Term [2009] UKSC 15  On appeal from...</td>\n",
       "      <td>[stone, king, sewell, british, aileen, first, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>Michaelmas Term [2009] UKSC 16 On appeal from:...</td>\n",
       "      <td>[civ, mahad, treasury, five, third, three, two...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>Michaelmas Term [2009] UKSC 16 On appeal from:...</td>\n",
       "      <td>[civ, mahad, treasury, five, third, three, two...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>Michaelmas Term [2009] UKSC 16 On appeal from:...</td>\n",
       "      <td>[civ, mahad, treasury, five, third, three, two...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>Michaelmas Term [2009] UKSC 17 On appeal from:...</td>\n",
       "      <td>[trafford, borough, council, legal, democratic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>946 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    Hilary Term [2022] UKSC 6 On appeal from: [202...   \n",
       "1    The reporting restrictions made by the High Co...   \n",
       "2    Hilary Term [2022] UKSC 2 On appeal from: [202...   \n",
       "3    Hilary Term [2022] UKSC 2 On appeal from: [202...   \n",
       "4    THE COURT ORDERED that no one shall publish or...   \n",
       "..                                                 ...   \n",
       "941  Michaelmas Term [2009] UKSC 15  On appeal from...   \n",
       "942  Michaelmas Term [2009] UKSC 16 On appeal from:...   \n",
       "943  Michaelmas Term [2009] UKSC 16 On appeal from:...   \n",
       "944  Michaelmas Term [2009] UKSC 16 On appeal from:...   \n",
       "945  Michaelmas Term [2009] UKSC 17 On appeal from:...   \n",
       "\n",
       "                                            clean_text  \n",
       "0    [lloyd, jones, scottish, european, convention,...  \n",
       "1    [lloyd, jones, bloomberg, news, one, supreme, ...  \n",
       "2    [lloyd, jones, birnberg, peirce, ltd, european...  \n",
       "3    [lloyd, jones, birnberg, peirce, ltd, european...  \n",
       "4    [british, government, legal, department, amnes...  \n",
       "..                                                 ...  \n",
       "941  [stone, king, sewell, british, aileen, first, ...  \n",
       "942  [civ, mahad, treasury, five, third, three, two...  \n",
       "943  [civ, mahad, treasury, five, third, three, two...  \n",
       "944  [civ, mahad, treasury, five, third, three, two...  \n",
       "945  [trafford, borough, council, legal, democratic...  \n",
       "\n",
       "[946 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc['clean_text'] = dfc.clean_text.apply(remove_final)\n",
    "dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08149a1c",
   "metadata": {},
   "source": [
    "# LDA : extract topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fda70f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc['clean_text'] = dfc['clean_text'].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a66e178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "data_vectorized = vectorizer.fit_transform(dfc['clean_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_idf_vectorizer = TfidfVectorizer(ngram_range = (2,2))\n",
    "\n",
    "# X = tf_idf_vectorizer.fit_transform(texts)\n",
    "\n",
    "# X.toarray()\n",
    "\n",
    "# pd.DataFrame(X.toarray(),columns = tf_idf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bdd6834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=20, learning_method='online')\n",
    "\n",
    "lda_vectors = lda_model.fit_transform(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d18a0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('leighton', 5.973926771015396), ('berwin', 5.629273738554441), ('woman', 2.7029599381506446), ('paisner', 2.6804645732361694), ('ec', 2.576908432795442), ('assessment', 2.401710237908965), ('euro', 1.985676416580449), ('leverton', 1.8185016250826938), ('holiday', 1.8182187755953116), ('dollar', 1.8003586501840936)]\n",
      "Topic 1:\n",
      "[('bond', 2.4311675479918224), ('bail', 1.6413229945292496), ('initio', 0.8935053823005197), ('arrest', 0.8424878149121915), ('moorland', 0.8390583133085939), ('void', 0.83886284849497), ('narrower', 0.8386979966653643), ('glasbrook', 0.8383726874030322), ('loucas', 0.8383510076364973), ('aylmerton', 0.8382864047043291)]\n",
      "Topic 2:\n",
      "[('respondent', 0.05467791222553416), ('two', 0.05452411010758935), ('conditional', 0.054466453331343236), ('christian', 0.05445756457859115), ('convention', 0.054451084023236986), ('lloyd', 0.054427947722018734), ('parliament', 0.05442577617031691), ('british', 0.0543679058666801), ('ii', 0.054357392471956784), ('scottish', 0.0543395936570248)]\n",
      "Topic 3:\n",
      "[('ka', 13.647227251469694), ('mahad', 13.585349560027662), ('ayan', 13.562024716682263), ('birmingham', 10.107115845339786), ('wolverhampton', 9.614398790112519), ('university', 8.210692970426987), ('muslim', 7.7019775734469915), ('single', 7.2418537655519994), ('thousand', 6.716651361024838), ('runa', 6.659175867191617)]\n",
      "Topic 4:\n",
      "[('principal', 2.339634398762201), ('directive', 1.6535012431819938), ('ministero', 1.5060811948222732), ('model', 0.8391094720768324), ('interest', 0.8389987008413333), ('amtfs', 0.8389780914530826), ('therein', 0.838955697917627), ('fisher', 0.8389390750043626), ('entire', 0.8389192574804545), ('allocation', 0.8388054048425292)]\n",
      "Topic 5:\n",
      "[('regulation', 0.05216700117592352), ('andrew', 0.05210700229119445), ('morley', 0.05210666817475563), ('kellett', 0.05210372518691284), ('western', 0.052100082873123024), ('organisation', 0.052062613337392705), ('gothenburg', 0.052056030250526686), ('pakistan', 0.052036119446817436), ('hargrave', 0.05202615282400926), ('memorandum', 0.052019817126536784)]\n",
      "Topic 6:\n",
      "[('normal', 13.616333714789606), ('working', 10.361933539302212), ('son', 10.360046171567973), ('american', 9.031200796987381), ('mile', 8.857320866661262), ('parochial', 8.56563643673423), ('mason', 8.521391853275938), ('billesley', 7.5947659161118075), ('lloyd', 7.532873182492112), ('agency', 7.1604096439664024)]\n",
      "Topic 7:\n",
      "[('ullah', 6.613470188142995), ('bircham', 5.420726245580433), ('dyson', 5.420014094855397), ('paterson', 3.268216533059907), ('litre', 3.117492051858639), ('oban', 3.115756198414322), ('tomorrow', 3.113986423643027), ('proposition', 3.1132450124129036), ('spielmann', 3.1127286238649883), ('miranda', 3.111153438423405)]\n",
      "Topic 8:\n",
      "[('metre', 14.843692967198315), ('royal', 12.314372993608337), ('turner', 11.48449461242308), ('star', 10.764047901850219), ('lewis', 10.195870469906053), ('million', 9.75051146292989), ('sun', 9.699732411897893), ('ocean', 9.260169672193506), ('zurich', 8.593328072150396), ('mile', 8.203793572404223)]\n",
      "Topic 9:\n",
      "[('une', 9.306631633848129), ('iii', 8.891400211939299), ('commerce', 7.767475528868645), ('million', 6.277252753958308), ('dicey', 6.27397111111502), ('nigeria', 5.421860302887666), ('libyan', 4.14944080563707), ('affair', 3.810026040971974), ('connecticut', 3.720460347066388), ('swiss', 3.6339612400574506)]\n",
      "Topic 10:\n",
      "[('counsel', 1.6204412481058212), ('conditional', 0.08529572640524813), ('third', 0.05798330104991897), ('secondly', 0.05797427199848351), ('european', 0.05751398498129517), ('para', 0.05748380865453015), ('supreme', 0.05742346727722457), ('three', 0.057320342829867456), ('court', 0.05704492542761282), ('first', 0.05693917860092583)]\n",
      "Topic 11:\n",
      "[('guardian', 0.0521351410944327), ('spinner', 0.05211020724889564), ('majesty', 0.052069715983130135), ('farrell', 0.05206874424317504), ('singular', 0.05206230675888063), ('italiana', 0.05205655400350255), ('mifid', 0.05205492960251703), ('rdss', 0.0520426654996191), ('grobelaar', 0.052042299284545214), ('anheuser', 0.05204015559688819)]\n",
      "Topic 12:\n",
      "[('cooper', 7.407306331830062), ('trustee', 5.5297540684668816), ('letang', 2.7736002614423283), ('name', 2.772372520639382), ('unicos', 2.770498428079885), ('chatsworth', 2.7686109506574863), ('cussins', 2.7674569127726545), ('bradstock', 2.766433213020817), ('staff', 2.3197428746595765), ('mihlenstedt', 2.010333695284057)]\n",
      "Topic 13:\n",
      "[('inc', 12.437030064199908), ('co', 8.79638035917782), ('federal', 8.480753029979839), ('standard', 7.592375390812806), ('qcs', 7.396959081838348), ('millett', 6.808000894313434), ('chinese', 6.797169709844628), ('ch', 6.6847883688204295), ('sixty', 6.525111628751581), ('per', 6.43859185344313)]\n",
      "Topic 14:\n",
      "[('govan', 1.735541416926752), ('kvaerner', 1.734953700542182), ('grange', 0.941715581898046), ('letham', 0.9174120012844468), ('duthie', 0.8387441974702382), ('bukta', 0.8387156787337167), ('fix', 0.8386684792657213), ('parade', 0.8384500841959616), ('verfahrens', 0.83843571341414), ('moment', 0.8364199235910617)]\n",
      "Topic 15:\n",
      "[('metix', 1.0726757057524834), ('congoleum', 1.0726150659696978), ('mannington', 1.0725999536651032), ('intl', 1.0725782811253048), ('gahagan', 1.0724051418846412), ('tyburn', 1.0721274207622618), ('billiton', 1.072031925725767), ('plastic', 1.0719704533906833), ('champion', 1.07119632907618), ('fair', 1.0710380070346883)]\n",
      "Topic 16:\n",
      "[('two', 880.183803184685), ('first', 879.4800966327462), ('one', 837.0666965212546), ('second', 813.7230439242938), ('three', 775.4603151110368), ('third', 714.5903386503934), ('secondly', 620.4903598796852), ('court', 599.7807245586172), ('european', 582.6453312638565), ('house', 514.3584654497679)]\n",
      "Topic 17:\n",
      "[('security', 15.096953358426585), ('al', 14.789749431231446), ('casting', 12.339640100124884), ('berrymans', 11.651965120185455), ('scrutton', 11.130294246946711), ('armed', 10.82266453524515), ('force', 10.69451377669664), ('iraqi', 10.065377999306584), ('rix', 9.939527543564234), ('akzo', 9.863143908318454)]\n",
      "Topic 18:\n",
      "[('solicitor', 12.559130897807105), ('crown', 12.37819984564971), ('kingdom', 11.786997068048409), ('united', 11.232326992983278), ('hundred', 11.056718990724855), ('mr', 10.75631512443926), ('common', 10.650020628295565), ('turkish', 10.385665023644886), ('committee', 10.296951897526865), ('commission', 10.282226433264334)]\n",
      "Topic 19:\n",
      "[('common', 0.052521839404348486), ('first', 0.05233231722791239), ('intervener', 0.05232272523146855), ('privy', 0.052302660314378316), ('legal', 0.05223942587067547), ('de', 0.052202877048966576), ('convene', 0.052171378398467985), ('bell', 0.052147248067326187), ('select', 0.05213657639306949), ('act', 0.052134854208444)]\n"
     ]
    }
   ],
   "source": [
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])\n",
    "        \n",
    "\n",
    "print_topics(lda_model, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9a9903",
   "metadata": {},
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "X_ngram = vectorizer.fit_transform(data.clean_reviews)\n",
    "\n",
    "cv_nb = cross_validate( MultinomialNB(), X_ngram, data.target, scoring = \"accuracy\")\n",
    "\n",
    "cv_nb['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb7722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline\n",
    "\n",
    "# Set parameters to search (model and vectorizer)\n",
    "\n",
    "# Perform grid search on pipeline\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.pipeline import Pipeline\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create Pipeline\n",
    "#pipeline = Pipeline([\n",
    "  #  ('tfidf', TfidfVectorizer()),\n",
    " #   ('nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Set parameters to search\n",
    "# parameters = {\n",
    "  #  'tfidf__ngram_range': ((1,1), (2,2)),\n",
    "  #  'tfidf__min_df': (0.05,0.1),\n",
    "  #  'tfidf__max_df': (0.75,1),\n",
    "  #  'nb__alpha': (0.01,0.1,1,10),}\n",
    "\n",
    "# Perform grid search on pipeline\n",
    "# grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, \n",
    "    #                       verbose=1, scoring = \"accuracy\", \n",
    "       #                    refit=True, cv=5)\n",
    "\n",
    "# grid_search.fit(data.clean_reviews,data.target)\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa770672",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068de6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd9a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagged_document(list_of_list_of_words):\n",
    "   for i, list_of_words in enumerate(list_of_list_of_words):\n",
    "      yield TaggedDocument(list_of_words, [i])\n",
    "data_for_training = list(tagged_document(dfc['clean_text']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34471ab9",
   "metadata": {},
   "source": [
    "#### Once trained we now need to initialise the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cd6f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents = data_for_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65f7f5",
   "metadata": {},
   "source": [
    "#### Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47675b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(data_for_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f1839",
   "metadata": {},
   "source": [
    "#### Train the Doc2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a6fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(data_for_training, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583d336c",
   "metadata": {},
   "source": [
    "## Analysing the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5ef038",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = model.infer_vector(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60d0770",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9313da05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7db60cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
