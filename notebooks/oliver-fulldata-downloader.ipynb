{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f99c7d5-f32d-4b5b-bd5e-11d7d76a2750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas_jsonlines.read_jsonlines import read_jsonlines\n",
    "import requests\n",
    "from translating_the_law.downloading.get_details import details_new, details_old\n",
    "import urllib.request\n",
    "import os\n",
    "import re\n",
    "from pdfminer.high_level import extract_text\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19c56e3d-510e-454e-9f80-0429c4b452ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = read_jsonlines(\"all.jsonlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1e677fa-ef00-4baa-81f1-e425a3ffa6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bee3026b-e84c-4b29-886f-0ea37baf3118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleanlinks():\n",
    "    links = read_jsonlines(\"all.jsonlines\")\n",
    "    clean_links = []\n",
    "    for link in links.dropna().iterrows():\n",
    "        sc_link = \"https://www.supremecourt.uk\"\n",
    "        base_url = link[1]['link'].split()[2][:-1].strip()\n",
    "        j_link = link[1]['judgment_link'].strip()\n",
    "        s_link = link[1]['pdf_link'].strip()\n",
    "        if j_link.startswith(\"/cases/docs\"):\n",
    "            j_link = sc_link + j_link\n",
    "        elif j_link.startswith(\"docs/\"):\n",
    "            j_link = sc_link + \"/cases/\" + j_link\n",
    "        else:\n",
    "            j_link = sc_link + \"/cases/docs\" + j_link\n",
    "        if s_link.endswith(\".html\"):\n",
    "            s_link = sc_link + s_link\n",
    "        elif s_link.startswith(\"/cases\"):\n",
    "            s_link = sc_link + s_link\n",
    "        else:\n",
    "            s_link = sc_link + \"/cases/\" + s_link\n",
    "        clean_links.append({\"base\":base_url, \"judgment\":j_link, \"summary\":s_link})\n",
    "        #if link[0] == 318 or  link[0] == 333 or  link[0] == 413:\n",
    "        #    x = requests.get(j_link)\n",
    "        #    if x.status_code != 200:\n",
    "        #        print(link[0], j_link)\n",
    "        #    x = requests.get(s_link)\n",
    "        #    if x.status_code != 200:\n",
    "        #        print(link[0], s_link)\n",
    "    return clean_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74470d8c-8bcd-4b6a-97c4-069f3bc919fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_extract_judgement(case):\n",
    "    main_text_file = f\"{case}-main-text.pdf\"\n",
    "    judgement = extract_text(main_text_file)\n",
    "    return judgement\n",
    "\n",
    "def alt_extract_press_summary(case, html_link=None):\n",
    "    if not html_link:\n",
    "        press_summary_file = f\"{case}-press-summary.pdf\"\n",
    "        summary = extract_text(press_summary_file)\n",
    "    else:\n",
    "        url = html_link\n",
    "        html = requests.get(url).content\n",
    "        soup = BeautifulSoup(html)\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.decompose()\n",
    "        strips = list(soup.stripped_strings)\n",
    "        summary = {}\n",
    "        for i, strip in enumerate(strips):\n",
    "            judges = 0\n",
    "            background = 0\n",
    "            judgment = 0\n",
    "            reasons = 0\n",
    "            if strip == \"Justices\":\n",
    "                print(i)\n",
    "                judges = i\n",
    "                print(strip)\n",
    "            elif strip == \"Background to the Appeal\":\n",
    "                print(i)\n",
    "                background = i\n",
    "                print(strip)\n",
    "            elif strip == \"Judgment\":\n",
    "                print(i)\n",
    "                judgment = i\n",
    "                print(strip)\n",
    "            elif strip == \"Reasons for the Judgment\":\n",
    "                print(i)\n",
    "                reasons = i\n",
    "                print(strip)\n",
    "            summary[\"Press summary\"] = \"\".join(strips[:judges])\n",
    "            summary[\"Justices\"] = \"\".join(strips[judges+1:background])\n",
    "            summary[\"Background to the appeal\"] = \"\".join(strips[background+1:judgment])\n",
    "            summary[\"Judgment\"] = \"\".join(strips[judgment+1:reasons])\n",
    "            summary[\"Reasons for the judgment\"] = \"\".join(strips[reasons + 1:])\n",
    "    return summary\n",
    "\n",
    "def alt_extract_details(url):\n",
    "    html = requests.get(url).content\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    strips = list(soup.stripped_strings)\n",
    "    if 'Facts' in strips:\n",
    "        details = details_new(strips)\n",
    "    else:\n",
    "        details = details_old(strips)\n",
    "    details['URL'] = url\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "689ad8f2-644d-4cf3-9065-8f828f445879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base': 'https://www.supremecourt.uk/cases/uksc-2020-0185.html',\n",
       " 'judgment': 'https://www.supremecourt.uk/cases/docs/uksc-2020-0185-judgment.pdf',\n",
       " 'summary': 'https://www.supremecourt.uk/press-summary/uksc-2020-0185.html'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "948df905-78e2-41d1-8fcf-810aa4e822b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_get_case_files(links):\n",
    "    case = links['base'].replace('.html', '').replace('https://www.supremecourt.uk/cases/','')\n",
    "    main_text_file = f\"{case}-main-text.pdf\"\n",
    "    press_summary_file = f\"{case}-press-summary.pdf\"\n",
    "    urllib.request.urlretrieve(links['judgment'], main_text_file)\n",
    "    if links['summary'].endswith(\".pdf\"):\n",
    "        urllib.request.urlretrieve(links['summary'], press_summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba845b31-4491-49e4-9894-4705b9d45d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_delete_case_files(links):\n",
    "    case = links['base'].replace('.html', '').replace('https://www.supremecourt.uk/cases/','')\n",
    "    main_text_file = f\"{case}-main-text.pdf\"\n",
    "    press_summary_file = f\"{case}-press-summary.pdf\"\n",
    "    os.system(f\"rm -rf {main_text_file}\")\n",
    "    if links['summary'].endswith(\".pdf\"):\n",
    "        os.system(f\"rm -rf {press_summary_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a1f04d0-2523-458b-bea8-6149d9cf5196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_extract_judgement(case):\n",
    "    case = case['base'].replace('.html', '').replace('https://www.supremecourt.uk/cases/','')\n",
    "    main_text_file = f\"{case}-main-text.pdf\"\n",
    "    judgement = extract_text(main_text_file)\n",
    "    return judgement\n",
    "\n",
    "def alt_extract_press_summary(case):\n",
    "    if case['summary'].endswith(\".pdf\"):\n",
    "        case = case['base'].replace('.html', '').replace('https://www.supremecourt.uk/cases/','')\n",
    "        press_summary_file = f\"{case}-press-summary.pdf\"\n",
    "        summary = extract_text(press_summary_file)\n",
    "    else:\n",
    "        url = case['summary']\n",
    "        html = requests.get(url).content\n",
    "        soup = BeautifulSoup(html)\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.decompose()\n",
    "        strips = list(soup.stripped_strings)\n",
    "        summary = {}\n",
    "        for i, strip in enumerate(strips):\n",
    "            judges = 0\n",
    "            background = 0\n",
    "            judgment = 0\n",
    "            reasons = 0\n",
    "            if strip == \"Justices\":\n",
    "                judges = i\n",
    "            elif strip == \"Background to the Appeal\":\n",
    "                background = i\n",
    "            elif strip == \"Judgment\":\n",
    "                judgment = i\n",
    "            elif strip == \"Reasons for the Judgment\":\n",
    "                reasons = i\n",
    "            summary[\"Press summary\"] = \"\".join(strips[:judges])\n",
    "            summary[\"Justices\"] = \"\".join(strips[judges+1:background])\n",
    "            summary[\"Background to the appeal\"] = \"\".join(strips[background+1:judgment])\n",
    "            summary[\"Judgment\"] = \"\".join(strips[judgment+1:reasons])\n",
    "            summary[\"Reasons for the judgment\"] = \"\".join(strips[reasons + 1:])\n",
    "    return summary\n",
    "\n",
    "def alt_extract_details(case):\n",
    "    url = case['base']\n",
    "    html = requests.get(url).content\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    strips = list(soup.stripped_strings)\n",
    "    if 'Facts' in strips:\n",
    "        details = details_new(strips)\n",
    "    else:\n",
    "        details = details_old(strips)\n",
    "    details['URL'] = url\n",
    "    return details\n",
    "\n",
    "def alt_extract_all(case):\n",
    "    j = alt_extract_judgement(case)\n",
    "    ps = alt_extract_press_summary(case)\n",
    "    d = alt_extract_details(case)\n",
    "    return j, ps, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2be63066-6ea6-4a41-8428-c065c6d053b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def judgement_to_dict(judgement):\n",
    "    judgement = judgement.replace(\"\\n\", \"\").strip()\n",
    "    return {\"body\":judgement}\n",
    "\n",
    "def summary_to_dict(summary, summary_url):\n",
    "    summary_regex = r\"PRESS SUMMARY(.*)JUSTICES:(.*)BACKGROUND TO THE APPEAL(.*)JUDGMENT(.*)REASONS FOR THE JUDGMENT(.*)\"\n",
    "    summary = summary.replace(\"\\n\", \"\").strip()\n",
    "    search = re.search(summary_regex,summary,flags=re.M)\n",
    "    if search:\n",
    "        return {\n",
    "            \"Press summary\":search.group(1).strip(),\n",
    "            \"Justices\":search.group(2).strip(),\n",
    "            \"Background to the appeal\":search.group(3).strip(),\n",
    "            \"Judgment\":search.group(4).strip(),\n",
    "            \"Reasons for the judgment\":search.group(5).strip()\n",
    "        }\n",
    "    return {\"error\": summary_url}\n",
    "\n",
    "def parse_all(judgement, summary, summary_url, details):\n",
    "    j = judgement_to_dict(judgement)\n",
    "    if type(summary) != dict:\n",
    "        ps = summary_to_dict(summary, summary_url)\n",
    "    else:\n",
    "        ps = summary\n",
    "    d = details\n",
    "    return {'judgement':j, 'press summary':ps, 'details':d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c47b2f5-b0f5-487b-b066-87114007218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset():\n",
    "    base_path = os.path.dirname(os.path.realpath(__file__))\n",
    "    save_path = os.path.join(base_path, \"..\", \"raw_data\", \"data.json\")\n",
    "    links = get_cleanlinks()\n",
    "    data = []\n",
    "    i = 0\n",
    "    for case in links:\n",
    "        i += 1\n",
    "        if i>=5:\n",
    "            break\n",
    "        alt_get_case_files(case)\n",
    "        j, ps, d = alt_extract_all(case)\n",
    "        data.append(parse_all(j, ps, case['summary'],d))\n",
    "        alt_delete_case_files(case)\n",
    "    json_string = json.dumps(data)\n",
    "    with open(save_path, 'w') as outfile:\n",
    "        json.dump(json_string, outfile)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01837b06-9002-4e9d-a595-61362bf9d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98560bc-98ee-4f39-a599-8dbf510853c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
